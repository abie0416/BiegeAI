#!/usr/bin/env python3
"""
Initialize the knowledge base with sample data for testing RAG functionality.
"""

import logging
import os
import shutil
from db.chroma_client import add_documents_to_vectorstore, get_vectorstore
from utils.environment import is_railway_environment, log_environment_info
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.schema import Document

# Get logger for this module
logger = logging.getLogger(__name__)

# Sample knowledge base data - longer texts for better chunking demonstration
sample_documents = [
    "Ericæ˜¯Oå­å­ï¼Œä»–éå¸¸å­é¡ºçˆ¶æ¯ï¼Œç»å¸¸å¸®åŠ©å®¶é‡Œåšå®¶åŠ¡ã€‚Ericåœ¨æœ‹å‹ä¸­å¾ˆå—æ¬¢è¿ï¼Œå¤§å®¶éƒ½å–œæ¬¢å’Œä»–ä¸€èµ·ç©ã€‚",
    "EricæŠ•ç¯®è¿˜å¯ä»¥ï¼Œä½†æ˜¯æ²¡æœ‰zznå‡†ã€‚Ericåœ¨ç¯®çƒåœºä¸Šè¡¨ç°ä¸é”™ï¼Œä½†æ˜¯zznçš„æŠ•ç¯®æŠ€æœ¯æ›´åŠ ç²¾å‡†ï¼Œå‘½ä¸­ç‡æ›´é«˜ã€‚",
    "911æ¯”718ç‰›é€¼ï¼Œä¿æ—¶æ·911æ˜¯ç»å…¸è·‘è½¦ï¼Œæ€§èƒ½å“è¶Šã€‚718è™½ç„¶ä¹Ÿä¸é”™ï¼Œä½†åœ¨å¾ˆå¤šæ–¹é¢éƒ½ä¸å¦‚911å‡ºè‰²ã€‚",
    "é©¬æ£šæ˜¯è€å¸æœºï¼Œå¼€è½¦æŠ€æœ¯å¾ˆå¥½ï¼Œç»éªŒä¸°å¯Œã€‚ä»–ç»å¸¸å¼€è½¦å¸¦å¤§å®¶å‡ºå»ç©ï¼Œå¤§å®¶éƒ½è§‰å¾—åä»–çš„è½¦å¾ˆå®‰å…¨ã€‚",
    "Finalå…¨èƒ½ç‹ï¼Œåœ¨æ¸¸æˆFinalä¸­è¡¨ç°éå¸¸å‡ºè‰²ï¼Œå„ç§è§’è‰²éƒ½èƒ½ç©å¾—å¾ˆå¥½ã€‚ä»–æ˜¯å¤§å®¶å…¬è®¤çš„æ¸¸æˆé«˜æ‰‹ã€‚",
    "å°ç˜¦å“¥ç©é¸Ÿç‹™å¾ˆå‰å®³ï¼Œåœ¨å°„å‡»æ¸¸æˆä¸­ç‰¹åˆ«æ“…é•¿ä½¿ç”¨ç‹™å‡»æªã€‚ä»–çš„ç„å‡†æŠ€æœ¯éå¸¸ç²¾å‡†ï¼Œç»å¸¸èƒ½ä¸€æªçˆ†å¤´ã€‚",
    "æ®µç¥æ˜¯é“å…·ç‹ï¼Œåœ¨æ¸¸æˆä¸­ç‰¹åˆ«æ“…é•¿ä½¿ç”¨å„ç§é“å…·ã€‚ä»–å¯¹æ¸¸æˆé“å…·çš„ç†è§£å¾ˆæ·±ï¼Œæ€»èƒ½æ‰¾åˆ°æœ€æœ‰æ•ˆçš„ä½¿ç”¨æ–¹æ³•ã€‚",
    "å´éæ˜¯äºšé©¬é€ŠAIç‹ï¼Œåœ¨äºšé©¬é€Šå·¥ä½œï¼Œä¸“é—¨è´Ÿè´£AIç›¸å…³é¡¹ç›®ã€‚ä»–åœ¨äººå·¥æ™ºèƒ½é¢†åŸŸå¾ˆæœ‰ç»éªŒï¼ŒæŠ€æœ¯èƒ½åŠ›å¾ˆå¼ºã€‚",
    "abieå°±æ˜¯æ†‹å“¥ï¼Œè¿™æ˜¯ä»–çš„å¤–å·ã€‚abieæ€§æ ¼æ¯”è¾ƒå†…å‘ï¼Œä¸å¤ªçˆ±è¯´è¯ï¼Œæ‰€ä»¥å¤§å®¶å«ä»–æ†‹å“¥ã€‚",
    "æ†‹å“¥ç‰›é€¼ï¼Œè™½ç„¶abieæ¯”è¾ƒå†…å‘ï¼Œä½†æ˜¯ä»–çš„èƒ½åŠ›å¾ˆå¼ºï¼Œåœ¨å¾ˆå¤šæ–¹é¢éƒ½å¾ˆå‡ºè‰²ï¼Œå¤§å®¶éƒ½å¾ˆä½©æœä»–ã€‚",
]

# Enable metadata for better document organization
sample_metadatas = [
    {"source": "friends", "category": "person", "name": "Eric", "trait": "å­é¡º"},
    {"source": "gaming", "category": "skill", "name": "Eric", "game": "ç¯®çƒ", "comparison": "zzn"},
    {"source": "cars", "category": "comparison", "brand": "ä¿æ—¶æ·", "models": "911,718"},
    {"source": "friends", "category": "person", "name": "é©¬æ£š", "skill": "é©¾é©¶"},
    {"source": "gaming", "category": "skill", "name": "Final", "title": "å…¨èƒ½ç‹"},
    {"source": "gaming", "category": "skill", "name": "å°ç˜¦å“¥", "weapon": "ç‹™å‡»æª"},
    {"source": "gaming", "category": "skill", "name": "æ®µç¥", "specialty": "é“å…·"},
    {"source": "work", "category": "person", "name": "å´é", "company": "äºšé©¬é€Š", "field": "AI"},
    {"source": "friends", "category": "person", "name": "abie", "nickname": "æ†‹å“¥", "trait": "å†…å‘"},
    {"source": "friends", "category": "person", "name": "abie", "nickname": "æ†‹å“¥", "trait": "èƒ½åŠ›å¼º"},
]

def create_chunks_from_documents(documents, metadatas=None):
    """Create chunks from documents using text splitter"""
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=200,  # Smaller chunks for better retrieval
        chunk_overlap=50,  # Overlap to maintain context
        length_function=len,
        separators=["\n\n", "\n", "ã€‚", "ï¼", "ï¼Ÿ", ".", "!", "?", " ", ""]
    )
    
    all_chunks = []
    all_chunk_metadatas = []
    
    for i, doc in enumerate(documents):
        # Split the document into chunks
        chunks = text_splitter.split_text(doc)
        
        # Create metadata for each chunk
        base_metadata = metadatas[i] if metadatas and i < len(metadatas) else {"source": "unknown"}
        
        for j, chunk in enumerate(chunks):
            chunk_metadata = base_metadata.copy()
            chunk_metadata["chunk_index"] = str(j)
            chunk_metadata["total_chunks"] = str(len(chunks))
            chunk_metadata["original_document_index"] = str(i)
            
            # Ensure all metadata values are strings (ChromaDB requirement)
            for key, value in chunk_metadata.items():
                if not isinstance(value, (str, int, float, bool)) or value is None:
                    chunk_metadata[key] = str(value)
            
            all_chunks.append(chunk)
            all_chunk_metadatas.append(chunk_metadata)
    
    logger.info(f"Created {len(all_chunks)} chunks from {len(documents)} documents")
    return all_chunks, all_chunk_metadatas

def init_knowledge_base():
    """Initialize the knowledge base with sample data"""
    logger.info("Initializing knowledge base with sample data...")
    log_environment_info()
    
    try:
        chroma_db_path = "./chroma_db"
        
        if is_railway_environment():
            logger.info("ğŸš‚ Railway environment detected - using in-memory database")
            # Use in-memory database for Railway
            vectorstore = get_vectorstore()
            
            # Try to get collection count to see if it's empty
            try:
                collection = vectorstore._collection
                count = collection.count()
                logger.info(f"Existing database has {count} documents")
                
                if count > 0:
                    logger.info("âœ… Knowledge base already initialized with data")
                    return
            except Exception as e:
                logger.info(f"No existing collection found or error accessing: {e}")
            
            # Try to add documents to existing or new collection
            try:
                # Create chunks from documents
                chunks, chunk_metadatas = create_chunks_from_documents(sample_documents, sample_metadatas)
                add_documents_to_vectorstore(chunks, chunk_metadatas)
                logger.info("âœ… Knowledge base initialized successfully in Railway!")
                logger.info(f"Added {len(chunks)} chunks from {len(sample_documents)} documents to the vectorstore.")
                return
            except Exception as e:
                logger.warning(f"âš ï¸ Could not initialize database in Railway: {e}")
                logger.info("ğŸ”„ Continuing without persistent knowledge base - will use RAG only")
                return
        else:
            # Local development - use file-based database
            vectorstore = get_vectorstore()
            
            # Try to get collection count to see if it's empty
            try:
                collection = vectorstore._collection
                count = collection.count()
                logger.info(f"Existing database has {count} documents")
                
                if count > 0:
                    logger.info("âœ… Knowledge base already initialized with data")
                    return
            except Exception:
                logger.info("No existing collection found, will create new one")
            
            # Clear existing database if it exists but is empty or corrupted
            if os.path.exists(chroma_db_path):
                try:
                    logger.info("Clearing existing ChromaDB data...")
                    shutil.rmtree(chroma_db_path)
                    logger.info("âœ… Existing database cleared")
                except PermissionError:
                    logger.warning("âš ï¸ Could not clear existing database (files in use), will try to add to existing")
            
            # Initialize fresh vectorstore with chunks
            chunks, chunk_metadatas = create_chunks_from_documents(sample_documents, sample_metadatas)
            add_documents_to_vectorstore(chunks, chunk_metadatas)
            logger.info("âœ… Knowledge base initialized successfully!")
            logger.info(f"Added {len(chunks)} chunks from {len(sample_documents)} documents to the vectorstore.")
        
    except Exception as e:
        logger.error(f"âŒ Error initializing knowledge base: {e}")
        logger.info("ğŸ”„ Continuing without knowledge base - will use RAG only")
        # Don't raise the exception - let the app continue without the knowledge base

if __name__ == "__main__":
    init_knowledge_base() 